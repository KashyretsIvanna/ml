{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyretsIvanna/ml/blob/main/%D0%9F%D0%A0%D0%9E%D0%93%D0%9D%D0%9E%D0%97%D0%A3%D0%92%D0%90%D0%9D%D0%9D%D0%AF_%D0%9D%D0%90_%D0%9E%D0%A1%D0%9D%D0%9E%D0%92%D0%86_%D0%9A%D0%9B%D0%90%D0%A1%D0%98%D0%A4%D0%86%D0%9A%D0%90%D0%A2%D0%9E%D0%A0%D0%90_%D0%94%D0%95%D0%A0%D0%95%D0%92%D0%90_%D0%A0%D0%86%D0%A8%D0%95%D0%9D%D0%AC_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Лабораторна робота 3**\n",
        "\n",
        "\n",
        "\n",
        "ВИКОРИСТАННЯ ЗГОРТКОВОЇ НЕЙРОННОЇ МЕРЕЖІ CNN\n",
        "ДЛЯ ЗАДАЧІ КЛАСИФІКАЦІЇ ЗОБРАЖЕНЬ\n",
        "\n",
        "Виконала студентка КП-41мп\n",
        "\n",
        "Каширець Іванна\n",
        "\n",
        "2025\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CvZZFG9eCy80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Завдання\n",
        "\n",
        "Потрібно використати бібліотеки мови програмування Python для\n",
        "завантаження, дослідження та аналізу набору даних Fashion-MNIST для задачі\n",
        "класифікації зображень. Після цього потрібно провести попередню обробку\n",
        "даних: змінити розміри, масштабувати, перетворити мітки у вектори\n",
        "кодування та розділити дані на навчальні та тестові набори. Зробивши все це,\n",
        "потрібно побудувати модель нейронної мережі CNN. Далі потрібно\n",
        "компілювати, навчити та оцінити побудовану модель, візуалізуючи точність і\n",
        "графіки втрат.\n",
        "\n",
        "Потрібно забезпечити уникнення перенавчання моделі, переглянути\n",
        "свою початкову модель і повторно навчити її. Потрібно оцінити нову модель і\n",
        "порівняти результати обох моделей. Зробіть прогнози на основі даних тесту,\n",
        "перетворіть ймовірності у мітки класів і побудуйте кілька тестових зразків, які\n",
        "модель правильно та неправильно класифікувала. Нарешті, потрібно\n",
        "візуалізувати звіт про класифікацію, який дасть вам більш глибоку\n",
        "інформацію про те, який клас був (не)правильно класифікований моделлю.\n",
        "Дайте відповіді на всі питання, поставені у ході виконання практикуму."
      ],
      "metadata": {
        "id": "ae2Dr7oLzPtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Реалізація"
      ],
      "metadata": {
        "id": "G31mWl9L6u88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Проаналізуйте дані"
      ],
      "metadata": {
        "id": "iIOtA02x8BYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Завантаження даних"
      ],
      "metadata": {
        "id": "5pYT4Vjy6nM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "iIibZb2Y61eI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Проаналізуйе дані"
      ],
      "metadata": {
        "id": "Kr0R0Kwv7QXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
        "print('Testing data shape : ', test_X.shape, test_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuNAau1a7DWM",
        "outputId": "4fa9457b-48dd-4e68-ff16-9f9d7f0c0f51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape :  (60000, 28, 28) (60000,)\n",
            "Testing data shape :  (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок:\n",
        "\n",
        "Навчальні дані складаються з 60 000 зображень розміром 28 на 28 пікселів. Це означає, що кожне зображення — це сітка з 28 рядків і 28 стовпців пікселів у відтінках сірого. Для кожного з цих зображень є відповідна мітка — одне число від 0 до 9, яке вказує, яка цифра зображена.\n",
        "\n",
        "Тестові дані містять 10 000 подібних зображень і міток. Ці зображення не використовуються в процесі навчання моделі, а натомість застосовуються для перевірки її якості — тобто, як добре модель навчилася розпізнавати цифри, які вона раніше не бачила.\n",
        "\n",
        "Таким чином, розмір навчального набору становить 60 000 зразків, а тестового — 10 000 зразків. Кожен зразок — це окреме зображення цифри у форматі 28×28 пікселів."
      ],
      "metadata": {
        "id": "gDwjFE6s7Sqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Знайдіть унікальні номери міток тренувального набору."
      ],
      "metadata": {
        "id": "gmFubZBE7fJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(train_Y)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mG6R74P7dRy",
        "outputId": "aeed4e2e-3b8f-4aba-bbf8-7b48a28b5986"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of outputs :  10\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Є десять вихідних класів від 0 до 9."
      ],
      "metadata": {
        "id": "iqFg-nOL7rIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Прогляньте зображення у наборі даних"
      ],
      "metadata": {
        "id": "9m7mLrlx7u8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[5,5])\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_X[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(test_X[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "csQRor4t7v1D",
        "outputId": "ef78f39e-06a2-4198-bdb0-c85b094ded4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 9')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Результати двох вищевказаних графіків виглядають як ботильйони, і\n",
        "цьому класу присвоєно мітку класу 9. Аналогічно, інші продукти будуть мати\n",
        "різні мітки, але подібні продукти будуть мати однакові мітки. Це означає, що\n",
        "усі 7000 зображень ботильйонів будуть мати мітку класу 9."
      ],
      "metadata": {
        "id": "uoqZC2NA72ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IflbCCuR79uY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Попередня обробка даних"
      ],
      "metadata": {
        "id": "JcA18oqw8EVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) перетворимо кожне зображення тренувального і\n",
        "тестового набору розміром 28x28 у матрицю розміром 28x28x1, яка подається\n",
        "в мережу."
      ],
      "metadata": {
        "id": "5J6F9kBr8HfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.reshape(-1, 28,28, 1)\n",
        "test_X = test_X.reshape(-1, 28,28, 1)\n",
        "train_X.shape, test_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7StWZm568UJF",
        "outputId": "a1ad8334-8819-4148-9264-1027d1bf281b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок:Ці зміни означають, що ви додали нову \"канальну\" вісь до кожного зображення. Раніше зображення мали форму (28, 28) — тобто були двовимірними (рядки й стовпці пікселів). Тепер кожне зображення має форму (28, 28, 1), де 1 означає один канал, тобто зображення є одноканальним (чорно-білим).\n",
        "\n",
        "Цей формат є стандартним для подачі зображень у нейронну мережу (зокрема CNN), яка очікує 4-вимірний вхід:\n",
        "(кількість_зразків, висота, ширина, кількість_каналів)\n",
        "\n",
        "Отже:\n",
        "\n",
        "Зберено кількість зразків зразків — 60 000 для навчання та 10 000 для тестування.\n",
        "Самі зображення не змінено, лише додано вимір, який потрібен для сумісності з глибокими нейронними мережами."
      ],
      "metadata": {
        "id": "tkXwouka8WfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) перетворимо дані в float32"
      ],
      "metadata": {
        "id": "e1R8rBofA1bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255."
      ],
      "metadata": {
        "id": "5QMi5nLCA4B8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) перетворимо навчальні та тестові мітки у вектори кодування:"
      ],
      "metadata": {
        "id": "cLw9M0bUA7F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the labels from categorical to one-hot encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "# Display the change for category label using one-hot encoding\n",
        "print('Original label:', train_Y[0])\n",
        "print('After conversion to one-hot:', train_Y_one_hot[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnmpqaXLB6jQ",
        "outputId": "56ba6b8e-1ed8-4cf6-c385-1d1dcedd02c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: 9\n",
            "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Раніше мітки класів (тобто правильні відповіді для кожного зображення) були представлені як цілі числа від 0 до 9. Наприклад, мітка 9 означає, що на зображенні зображено цифру 9.\n",
        "\n",
        "Після перетворення за допомогою функції to_categorical кожна така мітка стала вектором з 10 елементів, де:\n",
        "\n",
        "Всі елементи — це нулі, крім одного елемента з індексом, що відповідає мітці.\n",
        "\n",
        "Наприклад, мітка 9 стала вектором [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] — одиниця на 10-й позиції (індекс 9).\n",
        "\n"
      ],
      "metadata": {
        "id": "WtcwbrJkCKTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Розділимо дані та тестову тв тренувальну"
      ],
      "metadata": {
        "id": "-k0Qik7cCUCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X,\n",
        "train_Y_one_hot, test_size=0.2, random_state=13)"
      ],
      "metadata": {
        "id": "jei0EM-gCJqM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Перевіримо форму набору для навчання та перевірки."
      ],
      "metadata": {
        "id": "YE1KXoMHCcXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XkTdw95Cd7e",
        "outputId": "769ef62e-643d-4676-a305-eeb4c0b229d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Це означає, що дані розділено на навчальну та валідаційну частини. Під час тренування нейронної мережі модель навчається на 48 000 зразках (train_X) і одночасно перевіряє, як добре вона працює на валідаційному наборі з 12 000 зразків (valid_X). Це дозволяє відстежувати якість навчання та уникати перенавчання (overfitting).\n",
        "\n",
        "Також усі мітки вже перетворені у формат one-hot encoding, готовий для використання в нейронній мережі з функцією втрат, наприклад categorical_crossentropy.\n",
        "\n"
      ],
      "metadata": {
        "id": "EHQYuoTSChN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Нейронна мережа. Змоделюйте дані"
      ],
      "metadata": {
        "id": "qeWKakjOC2af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Імпортуємо необхідні бібліотеки"
      ],
      "metadata": {
        "id": "qHwoTv5hDNCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n"
      ],
      "metadata": {
        "id": "lAUTFDjNDKTo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n"
      ],
      "metadata": {
        "id": "248h24dKCyLG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 20\n",
        "num_classes = 10\n"
      ],
      "metadata": {
        "id": "NDtzGjW9D8Tb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Архітектура нейронної мережі"
      ],
      "metadata": {
        "id": "Mhvbh5AeEJuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_model = Sequential()\n",
        "\n",
        "fashion_model.add(Conv2D(32, kernel_size=(3,3), activation='linear', input_shape=(28,28,1), padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "fashion_model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "fashion_model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "fashion_model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_iLtBLSETiH",
        "outputId": "37ed1ede-f6a3-405b-f609-085fe6b08ecf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок: Модель приймає чорно-біле зображення 28x28 пікселів, Використовує кілька згорткових шарів для виділення ознак, Переходить до повнозв’язного шару для класифікації, повертає ймовірності належності до кожного з класів."
      ],
      "metadata": {
        "id": "OfSl_oj6Ep46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Компіляція моделі\n"
      ],
      "metadata": {
        "id": "3VJydPkmEqRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Після створення моделі компілюйте її за допомогою оптимізатора Adam,  одного з найпопулярніших алгоритмів оптимізації. Вкажіть тип втрат, який є  категоріальною перехресною ентропією, що використовується для  багатокласової класифікації, також можна використовувати двійкову  перехресну ентропію як функцію втрат. Вкажіть метрику як точність, яку  хочете проаналізувати під час навчання моделі."
      ],
      "metadata": {
        "id": "d9BC64O0FETg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "41yCm0xzE5Ps"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Вконайте візуалізацію шарів"
      ],
      "metadata": {
        "id": "WQG4HLn7FLOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "BtHbmqn3FL47",
        "outputId": "765943b2-a2a3-40ba-cda5-b8a4310d2057"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m356,234\u001b[0m (1.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,234</span> (1.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m356,234\u001b[0m (1.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,234</span> (1.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цей результат показує структуру побудованої згорткової нейронної мережі, яку ми створили за допомогою Keras. Модель має послідовну архітектуру, яка складається з 12 шарів. Кожен шар виконує певну роль у процесі обробки зображення 28×28 пікселів і класифікації його до одного з 10 класів.\n",
        "\n",
        "Conv2D (32 фільтри) — перший згортковий шар із 32 фільтрами розміром 3×3, який аналізує вхідне зображення. Після нього вихід має форму (28, 28, 32). Цей шар має 320 параметрів, які будуть навчатись.\n",
        "\n",
        "LeakyReLU — додає нелінійність до моделі. Параметрів для навчання не має.\n",
        "\n",
        "MaxPooling2D — зменшує розмір зображення вдвічі, до (14, 14, 32).\n",
        "\n",
        "Conv2D (64 фільтри) — другий згортковий шар із виходом (14, 14, 64) і 18,496 параметрами.\n",
        "\n",
        "LeakyReLU — знову вводить нелінійність, без параметрів.\n",
        "\n",
        "MaxPooling2D — зменшує розмір до (7, 7, 64).\n",
        "\n",
        "Conv2D (128 фільтрів) — третій згортковий шар із виходом (7, 7, 128) і 73,856 параметрами.\n",
        "\n",
        "LeakyReLU — нелінійна активація.\n",
        "\n",
        "MaxPooling2D — ще раз зменшує розмір до (4, 4, 128).\n",
        "\n",
        "Flatten — перетворює 3D-вихід у 1D-вектор з 2048 елементів.\n",
        "\n",
        "Dense (128 нейронів) — щільний шар з 128 нейронами та 262,272 параметрами. Тут модель починає \"розуміти\" ознаки зображень на абстрактному рівні.\n",
        "\n",
        "LeakyReLU — нелінійна функція активації.\n",
        "\n",
        "Dense (10 нейронів) — фінальний шар, який відповідає за класифікацію на 10 класів. Має 1,290 параметрів, а на виході дає ймовірності для кожного класу."
      ],
      "metadata": {
        "id": "0MVbc_OWFadO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Тренування моделі"
      ],
      "metadata": {
        "id": "6bHZvUcIFerm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_train = fashion_model.fit(train_X, train_label,\n",
        "batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Zhd0Gr72Fldt",
        "outputId": "6d8655a9-82ca-4b0c-ab69-1751e440fabc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m  4/750\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 178ms/step - accuracy: 0.8910 - loss: 0.2769"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4c00ebcd9e18>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fashion_train = fashion_model.fit(train_X, train_label, \n\u001b[0m\u001b[1;32m      2\u001b[0m batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label)) \n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Висновок\n",
        "\n"
      ],
      "metadata": {
        "id": "6Og29nwt2nwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У ході роботи було проведено аналіз набору даних про пасажирів «Титаніка» та побудовано модель дерева рішень для передбачення виживання.\n",
        "\n",
        "Основні результати:\n",
        "\n",
        "Найбільш значущою ознакою для класифікації виявився гендер, що підтверджує історичні дані про рятування жінок і дітей у першу чергу.\n",
        "Дерево рішень показало логічну структуру розбиття, де наступними важливими ознаками стали вік, клас каюти та вартість квитка.\n",
        "Усього вхідний набір містив 1308 записів, з яких були відсутні дані про вік у 263 записах.\n",
        "Після розділення вибірки на тренувальну (60%) і тестову (40%), модель показала наступні результати:\n",
        "\n",
        "Training accuracy = 82.0%\n",
        "Testing accuracy = 80.5%\n",
        "Це означає, що модель добре узагальнює результати і не має значного перенавчання.\n",
        "\n",
        "Можливі покращення:\n",
        "Додавання нових ознак (наприклад, об'єднання сімей, аналіз місця посадки).\n",
        "Тонке налаштування гіперпараметрів (глибина дерева, мінімальна кількість зразків у вузлах тощо).\n",
        "Спроба інших алгоритмів, таких як RandomForestClassifier або GradientBoostingClassifier, які можуть дати вищу точність.\n",
        "Загалом, отримана модель є інформативною, узгоджується з логічними припущеннями та може бути використана для подальших покращень."
      ],
      "metadata": {
        "id": "y80ntPfyyvxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Питання для самоперевірки\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AA7wMKSrQARe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1. Дайте визначення методу дерев рішень (decision trees).**\n",
        "Метод дерев рішень (decision trees) – це алгоритм машинного навчання, який\n",
        "використовується для класифікації та регресії. Він побудований у вигляді дерева, д\n",
        "е кожна вершина відповідає умовам поділу на основі певної ознаки, а кінцеві гілки дерева (листи)\n",
        "містять відповідні класи або значення. Дерева рішень використовуються для прийняття рішень, коли\n",
        "потрібно класифікувати дані або передбачити числові значення.\n",
        "\n",
        "**2. Як будуються та використовуються бінарні дерева?** Наведіть приклад.\n",
        "Будова та використання бінарних дерев: Бінарне дерево – це дерево, де кожен вузол має не більше\n",
        "двох нащадків. Це зручна структура для реалізації алгоритмів сортування, пошуку або аналізу даних.\n",
        "Наприклад, бінарне дерево пошуку (Binary Search Tree, BST) зберігає елементи так, що для кожного вузла\n",
        "елементи в лівому піддереві менші за значення вузла, а елементи в правому – більші. Використовується\n",
        "для швидкого пошуку елементів.\n",
        "\n",
        "**3. Які існують переваги методу дерева рішень?**\n",
        "Переваги методу дерева рішень:\n",
        "Легко інтерпретується і візуалізується.\n",
        "Не вимагає масштабування даних.\n",
        "Може працювати з як числовими, так і категоріальними ознаками.\n",
        "Швидко навчається та здатне працювати з великими обсягами даних.\n",
        "Можна використовувати для задач класифікації та регресії.\n",
        "\n",
        "**4. Які існують критерії розщеплення дерева рішень?**\n",
        "Критерії розщеплення дерева рішень:\n",
        "Інформаційний приріст (Information Gain): Використовується в ID3 та C4.5 для визначення, який атрибут найбільше зменшує невизначеність.\n",
        "Gini impurity: Використовується в CART (Classification and Regression Trees), вимірює ступінь чистоти підмножини.\n",
        "Коефіцієнт ентропії: Використовується для вимірювання нерівномірності даних у вузлі.\n",
        "\n",
        "**5. Які існують варіанти зупинки навчання дерева рішень?**\n",
        "Варіанти зупинки навчання дерева рішень:\n",
        "Досягнення максимального глибини дерева.\n",
        "Якщо кількість елементів у вузлі менша за мінімальний поріг.\n",
        "Якщо розщеплення більше не зменшує непевність.\n",
        "Якщо дерево досягає мінімальної кількості змін у розщепленнях.\n",
        "\n",
        "**6. Які інструменти Python використовуються для побудови дерева рішень?**\n",
        "Інструменти Python для побудови дерева рішень:\n",
        "Scikit-learn: Бібліотека для машинного навчання, яка включає реалізацію дерева рішень в класі DecisionTreeClassifier для класифікації та DecisionTreeRegressor для регресії.\n",
        "XGBoost: Покращений варіант алгоритму дерева рішень, оптимізований для високої продуктивності.\n",
        "Graphviz: Для візуалізації дерева рішень.\n",
        "\n",
        "**7. Як реалізовується оцінка моделі класифікатора дерева рішень?**\n",
        "Оцінка моделі класифікатора дерева рішень: Оцінка моделі дерева рішень зазвичай включає такі метрики:\n",
        "Точність (accuracy): Частка правильних прогнозів серед усіх прогнозів.\n",
        "Матриця сплутаності (confusion matrix): Для оцінки кількості істинно позитивних, істинно негативних, хибно позитивних і хибно негативних прогнозів.\n",
        "F1-міра: Враховує як точність, так і відгук, особливо корисно для незбалансованих класів.\n",
        "AUC-ROC: Площу під кривою прийняття характеристик (Receiver Operating Characteristic) для класифікаційних задач."
      ],
      "metadata": {
        "id": "6vndgZdf0FQo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}